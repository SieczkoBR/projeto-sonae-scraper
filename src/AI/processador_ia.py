import sqlite3
import os
import re
import logging

# --- Configura√ß√£o ---
CAMINHO_BANCO = os.path.join("data", "projetos_sonae.db")

# Criar diret√≥rio de logs se n√£o existir
os.makedirs("logs", exist_ok=True)

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join("logs", "ia_processing.log")),
        logging.StreamHandler()
    ]
)

def carregar_modelo():
    """
    Carrega o modelo FLAN-T5 para gera√ß√£o de texto.
    
    Returns:
        Pipeline do modelo ou None se falhar
    """
    try:
        from transformers import pipeline
        
        logging.info("Carregando modelo FLAN-T5...")
        
        modelo = pipeline(
            "text2text-generation",
            model="google/flan-t5-base",
            device=-1  # CPU
        )
        
        logging.info("Modelo FLAN-T5 carregado com sucesso!")
        return modelo
        
    except Exception as e:
        logging.error(f"Erro ao carregar modelo: {e}")
        return None

def gerar_relatorio_executivo(modelo, conteudo, tamanho, prompt_personalizado="", incluir_graficos=False):
    """
    Gera um relat√≥rio executivo completo analisando o conte√∫do fornecido.
    
    Args:
        modelo: Modelo FLAN-T5
        conteudo: Conte√∫do do arquivo para an√°lise
        tamanho: N√≠vel de detalhe (Muito Curto, Curto, M√©dio, Longo, Detalhado)
        prompt_personalizado: Instru√ß√µes adicionais do usu√°rio
        incluir_graficos: Se deve incluir an√°lise de dados para gr√°ficos (n√£o utilizado)
    
    Returns:
        dict: {"texto": str, "dados_graficos": dict}
    """
    try:
        # Limitar conte√∫do para n√£o sobrecarregar
        max_chars_map = {
            "Muito Curto": 3000,
            "Curto": 4000,
            "M√©dio": 5000,
            "Longo": 7000,
            "Detalhado": 10000
        }
        max_chars = max_chars_map.get(tamanho, 5000)
        
        if len(conteudo) > max_chars:
            conteudo = conteudo[:max_chars]
        
        # Determinar instru√ß√µes de tamanho
        tamanho_instrucoes = {
            "Muito Curto": "Seja MUITO CONCISO. M√°ximo 3-4 par√°grafos curtos.",
            "Curto": "Seja CONCISO. M√°ximo 5-6 par√°grafos.",
            "M√©dio": "Seja equilibrado. Entre 8-10 par√°grafos bem estruturados.",
            "Longo": "Seja DETALHADO. Entre 12-15 par√°grafos com an√°lise profunda.",
            "Detalhado": "Seja EXTREMAMENTE DETALHADO. An√°lise completa e aprofundada com todos os aspectos relevantes."
        }
        
        instrucao_tamanho = tamanho_instrucoes.get(tamanho, "Seja equilibrado e profissional.")
        
        # Construir prompt SIMPLES para FLAN-T5
        prompt = f"""Analise este documento e crie um relat√≥rio executivo profissional em portugu√™s.

Documento:
{conteudo}

Crie um relat√≥rio com estas 4 se√ß√µes:

1. An√°lise do Documento - Resuma o objetivo e contexto em 2-3 par√°grafos

2. Dados e Informa√ß√µes Relevantes - Liste os dados principais:
   - Percentuais e m√©tricas
   - Valores e or√ßamentos  
   - Datas e prazos
   - Status e respons√°veis

3. Insights Estrat√©gicos - Analise riscos, oportunidades e pontos de aten√ß√£o em 2-3 par√°grafos

4. Pr√≥ximas A√ß√µes Recomendadas - Liste 3-5 a√ß√µes pr√°ticas baseadas no documento

{instrucao_tamanho}
{f'Foco especial: {prompt_personalizado}' if prompt_personalizado else ''}

Relat√≥rio:"""
        
        # Gerar relat√≥rio com FLAN-T5
        logging.info(f"Gerando relat√≥rio executivo com FLAN-T5 (tamanho: {tamanho})")
        
        # Configura√ß√µes de gera√ß√£o
        max_length_map = {
            "Muito Curto": 256,
            "Curto": 512,
            "M√©dio": 768,
            "Longo": 1024,
            "Detalhado": 1536
        }
        
        resultado = modelo(
            prompt,
            max_length=max_length_map.get(tamanho, 768),
            min_length=100,
            temperature=0.7,
            do_sample=True,
            top_p=0.9
        )
        
        logging.info("Relat√≥rio gerado com sucesso pelo FLAN-T5!")
        texto_gerado = resultado[0]['generated_text']
        
        # Formata√ß√£o do relat√≥rio
        relatorio_formatado = _formatar_relatorio(texto_gerado, conteudo)
        
        # N√£o gerar gr√°ficos
        return {
            "texto": relatorio_formatado,
            "dados_graficos": None
        }
        
    except Exception as e:
        logging.error(f"Erro ao gerar relat√≥rio com FLAN-T5: {e}")
        # Retornar an√°lise b√°sica em caso de erro
        return {
            "texto": _gerar_relatorio_basico(conteudo, prompt_personalizado),
            "dados_graficos": None
        }

def _gerar_graficos_analise(conteudo):
    """Gera dados para gr√°ficos com base no conte√∫do analisado"""
    import re
    
    graficos = {}
    
    # Palavras-chave que indicam dados IRRELEVANTES (gen√©ricos/exemplos)
    palavras_irrelevantes = [
        'exemplo', 'modelo', 'template', 'amostra', 'ilustra√ß√£o',
        'hipot√©tico', 'fict√≠cio', 'simula√ß√£o', 'teste', 'demo'
    ]
    
    # Tentar extrair percentuais REAIS para gr√°fico de progresso
    percentuais_com_label = []
    
    # Padr√µes com PRIORIDADE (mais espec√≠ficos primeiro, gen√©ricos depois)
    padroes_prioritarios = [
        # Padr√£o 1: Lista com marcador (mais espec√≠fico)
        (r'[-‚Ä¢]\s*([A-Za-z√Ä-√ø][^:\n]{10,150}):\s*(\d+)%', 10),
        # Padr√£o 2: Lista invertida
        (r'[-‚Ä¢]\s*(\d+)%\s+(?:de\s+)?([A-Za-z√Ä-√ø][^\n]{10,100})', 9),
    ]
    
    padroes_genericos = [
        # Padr√£o 3: Label seguido de percentual (sem marcador)
        (r'([A-Za-z√Ä-√ø][^:\n]{10,100}):\s*(\d+)%', 5),
        # Padr√£o 4: Percentual seguido de label
        (r'(\d+)%\s+(?:de\s+)?([A-Za-z√Ä-√ø][^\n]{10,80})', 4),
        # Padr√£o 5: Label com verbo de conclus√£o
        (r'([A-Za-z√Ä-√ø][^\n]{10,80})\s+(?:est√°|atingiu|alcan√ßou)?\s*(?:em\s+)?(\d+)%', 3),
    ]
    
    linhas_conteudo = conteudo.split('\n')
    
    # Primeira passagem: tentar padr√µes priorit√°rios
    for linha in linhas_conteudo:
        linha_lower = linha.lower()
        
        # Ignorar linhas com palavras irrelevantes
        if any(palavra in linha_lower for palavra in palavras_irrelevantes):
            continue
        
        # Ignorar linha se for apenas t√≠tulo gen√©rico (como "conclu√≠do: 100%")
        if re.match(r'^\s*[a-z√ß]{1,15}\s*:\s*\d+%\s*$', linha.strip(), re.IGNORECASE):
            continue
        
        for padrao, prioridade in padroes_prioritarios:
            matches = re.findall(padrao, linha, re.IGNORECASE)
            for match in matches:
                if len(match) == 2:
                    label = match[0].strip() if not match[0].isdigit() else match[1].strip()
                    valor = match[1] if not match[0].isdigit() else match[0]
                    
                    try:
                        valor_num = int(valor)
                        if 0 < valor_num <= 100:
                            # Limpar sufixos desnecess√°rios do label
                            label_limpo = re.sub(r'\s+(conclu√≠do|conclu√≠da|finalizado|finalizada|completo|completa).*$', '', label, flags=re.IGNORECASE)
                            label_limpo = re.sub(r'[:\-]$', '', label_limpo).strip()
                            label_limpo = label_limpo[:60]
                            
                            # Validar tamanho m√≠nimo
                            if len(label_limpo) >= 8 and re.search(r'[a-zA-Z√Ä-√ø]{5,}', label_limpo):
                                # Evitar duplicatas
                                if not any(p['label'].lower() == label_limpo.lower() for p in percentuais_com_label):
                                    percentuais_com_label.append({
                                        'label': label_limpo,
                                        'valor': valor_num,
                                        'prioridade': prioridade
                                    })
                    except:
                        pass
    
    # Segunda passagem: se n√£o encontrou itens suficientes, usar padr√µes gen√©ricos
    if len(percentuais_com_label) < 2:
        for linha in linhas_conteudo:
            linha_lower = linha.lower()
            
            if any(palavra in linha_lower for palavra in palavras_irrelevantes):
                continue
            
            if re.match(r'^\s*[a-z√ß]{1,15}\s*:\s*\d+%\s*$', linha.strip(), re.IGNORECASE):
                continue
            
            for padrao, prioridade in padroes_genericos:
                matches = re.findall(padrao, linha, re.IGNORECASE)
                for match in matches:
                    if len(match) == 2:
                        label = match[0].strip() if not match[0].isdigit() else match[1].strip()
                        valor = match[1] if not match[0].isdigit() else match[0]
                        
                        try:
                            valor_num = int(valor)
                            if 0 < valor_num <= 100:
                                label_limpo = re.sub(r'\s+(conclu√≠do|conclu√≠da|finalizado|finalizada|completo|completa).*$', '', label, flags=re.IGNORECASE)
                                label_limpo = re.sub(r'[:\-]$', '', label_limpo).strip()
                                label_limpo = label_limpo[:60]
                                
                                # Para padr√µes gen√©ricos, ser um pouco mais flex√≠vel no tamanho
                                if len(label_limpo) >= 5 and re.search(r'[a-zA-Z√Ä-√ø]{3,}', label_limpo):
                                    if not any(p['label'].lower() == label_limpo.lower() for p in percentuais_com_label):
                                        percentuais_com_label.append({
                                            'label': label_limpo,
                                            'valor': valor_num,
                                            'prioridade': prioridade
                                        })
                        except:
                            pass
    
    # Gerar gr√°fico apenas se houver dados v√°lidos (m√≠nimo 2, m√°ximo 8)
    if len(percentuais_com_label) >= 2:
        # Ordenar por prioridade primeiro, depois por valor
        percentuais_com_label = sorted(percentuais_com_label, key=lambda x: (x['prioridade'], x['valor']), reverse=True)[:8]
        
        valores = [p['valor'] for p in percentuais_com_label]
        labels = [p['label'] for p in percentuais_com_label]
        
        graficos['progresso'] = {
            'tipo': 'barra',
            'valores': valores,
            'labels': labels,
            'titulo': 'Indicadores de Progresso do Projeto',
            'descricao': 'Percentuais de conclus√£o das diferentes etapas identificadas no documento. Estes dados representam o estado atual do projeto conforme documentado.'
        }
    
    return graficos if graficos else None

def _dividir_em_secoes(texto):
    """Divide o texto em se√ß√µes l√≥gicas baseado em pontos, n√∫meros ou t√≥picos"""
    import re
    
    # Tentar identificar se√ß√µes numeradas (1., 2., etc)
    secoes_numeradas = re.split(r'\n*\d+\.\s+', texto)
    if len(secoes_numeradas) > 2:  # Se encontrou se√ß√µes numeradas
        return [s.strip() for s in secoes_numeradas if s.strip()]
    
    # Tentar identificar por quebras de par√°grafo duplas
    paragrafos = texto.split('\n\n')
    if len(paragrafos) > 1:
        return [p.strip() for p in paragrafos if p.strip()]
    
    # Tentar dividir por senten√ßas e agrupar
    sentencas = re.split(r'(?<=[.!?])\s+', texto)
    
    if len(sentencas) <= 2:
        return [texto]
    
    # Agrupar em blocos de 2-3 senten√ßas
    secoes = []
    temp_secao = []
    
    for i, sentenca in enumerate(sentencas):
        temp_secao.append(sentenca)
        if len(temp_secao) >= 2 or i == len(sentencas) - 1:
            secoes.append(' '.join(temp_secao))
            temp_secao = []
    
    return secoes

def _formatar_relatorio(texto, conteudo_original):
    """
    Formata e estrutura o relat√≥rio gerado pelo FLAN-T5
    """
    import re
    
    # Se j√° tem estrutura de se√ß√µes, retornar
    if '##' in texto or '**An√°lise' in texto:
        return texto
    
    # Limpar e capitalizar
    texto = texto.strip()
    if texto and len(texto) > 0:
        texto = texto[0].upper() + texto[1:]
    
    # Dividir texto em frases para criar par√°grafos
    frases = re.split(r'\. ', texto)
    paragrafos = []
    paragrafo_atual = []
    
    for i, frase in enumerate(frases):
        paragrafo_atual.append(frase.strip())
        # Criar novo par√°grafo a cada 2-3 frases
        if (i + 1) % 2 == 0 or i == len(frases) - 1:
            if paragrafo_atual:
                paragrafos.append('. '.join(paragrafo_atual) + ('.' if not paragrafo_atual[-1].endswith('.') else ''))
                paragrafo_atual = []
    
    texto_formatado = '\n\n'.join(paragrafos)
    
    # Extrair dados do documento original
    dados_extraidos = _extrair_dados_contextualizados(conteudo_original)
    
    # Estruturar relat√≥rio
    relatorio = f"""## üìã An√°lise do Documento

{texto_formatado}

---

## üìä Dados e Informa√ß√µes Relevantes

"""
    
    # Adicionar dados extra√≠dos
    if dados_extraidos:
        for dado in dados_extraidos:
            if dado.get('categoria') and dado.get('valores'):
                relatorio += f"**{dado['categoria']}**\n\n"
                for valor in dado['valores'][:5]:  # Limitar a 5 itens
                    relatorio += f"- {valor}\n"
                relatorio += "\n"
    else:
        relatorio += "Dados estruturados n√£o identificados automaticamente.\n\n"
    
    relatorio += """---

## üí° Insights Estrat√©gicos

Baseado na an√°lise do documento:

- O projeto apresenta informa√ß√µes estruturadas que requerem aten√ß√£o executiva
- Recomenda-se valida√ß√£o dos dados apresentados para decis√µes estrat√©gicas
- Pontos de aten√ß√£o devem ser priorizados conforme impacto e urg√™ncia

---

## üéØ Pr√≥ximas A√ß√µes Recomendadas

1. Revisar dados e m√©tricas apresentadas no documento
2. Identificar prioridades e a√ß√µes cr√≠ticas
3. Estabelecer indicadores de acompanhamento
4. Documentar decis√µes e pr√≥ximos passos
5. Agendar revis√£o de progresso

"""
    
    return relatorio

def _extrair_dados_contextualizados(texto):
    """Extrai dados num√©ricos com contexto real do texto"""
    import re
    
    dados = []
    
    # Palavras-chave que indicam dados IRRELEVANTES
    palavras_irrelevantes = [
        'exemplo', 'modelo', 'template', 'amostra', 'ilustra√ß√£o',
        'hipot√©tico', 'fict√≠cio', 'simula√ß√£o', 'teste', 'demo',
        'padr√£o', 'gen√©rico', 'default'
    ]
    
    # Buscar percentuais com contexto mais amplo
    linhas = texto.split('\n')
    percentuais_encontrados = []
    
    for linha in linhas:
        # Ignorar linhas inteiras com palavras irrelevantes
        linha_lower = linha.lower()
        if any(palavra in linha_lower for palavra in palavras_irrelevantes):
            continue
        
        # Ignorar linhas gen√©ricas tipo "conclu√≠do: 100%" (t√≠tulos curtos)
        if re.match(r'^\s*[a-z√ß]{1,15}\s*:\s*\d+%\s*$', linha.strip(), re.IGNORECASE):
            continue
        
        # PRIORIDADE 1: Procurar padr√µes de lista com percentual
        # "- Desenvolvimento da estrutura: 100% conclu√≠do"
        match_lista = re.search(r'[-‚Ä¢]\s*([^:\n]{10,150}):\s*(\d+)%', linha, re.IGNORECASE)
        if match_lista:
            label = match_lista.group(1).strip()
            valor = match_lista.group(2)
            
            # Limpar sufixos desnecess√°rios
            label_limpo = re.sub(r'\s+(conclu√≠do|conclu√≠da|finalizado|finalizada|completo|completa).*$', '', label, flags=re.IGNORECASE)
            label_limpo = label_limpo.strip()
            
            # Validar
            if len(label_limpo) >= 8 and re.search(r'[a-zA-Z√Ä-√ø]{5,}', label_limpo):
                contexto = f"{label_limpo}: {valor}%"
                
                # Evitar duplicatas
                if not any(p['valor'] == valor and label_limpo.lower() in p['contexto'].lower() for p in percentuais_encontrados):
                    percentuais_encontrados.append({
                        'valor': valor,
                        'contexto': contexto,
                        'prioridade': 10
                    })
            continue
        
        # PRIORIDADE 2: Procurar outros padr√µes de percentual com contexto
        matches = re.finditer(r'(.{0,80})(\d+)%(.{0,80})', linha, re.IGNORECASE)
        for match in matches:
            contexto_antes = match.group(1).strip()
            valor = match.group(2)
            contexto_depois = match.group(3).strip()
            
            # Ignorar percentuais de 0% sem contexto relevante
            if valor == '0' and not any(palavra in linha_lower for palavra in ['progresso', 'conclus√£o', 'andamento', 'completo']):
                continue
            
            # Montar contexto completo
            contexto_completo = f"{contexto_antes} {valor}% {contexto_depois}".strip()
            
            # Limpar contexto de caracteres especiais no in√≠cio/fim
            contexto_completo = re.sub(r'^[:\-\s]+|[:\-\s]+$', '', contexto_completo)
            
            # Validar que o contexto tem pelo menos algum texto significativo
            texto_sem_percentual = contexto_completo.replace(f'{valor}%', '').strip()
            if len(texto_sem_percentual) < 8:  # Reduzido de 10 para 8 para ser mais flex√≠vel
                continue
            
            # Validar que tem texto alfab√©tico real (n√£o apenas n√∫meros/s√≠mbolos)
            if not re.search(r'[a-zA-Z√Ä-√ø]{4,}', texto_sem_percentual):  # Reduzido de 5 para 4
                continue
            
            # Evitar duplicatas exatas ou muito similares
            if not any(p['valor'] == valor and p['contexto'][:40] == contexto_completo[:40] for p in percentuais_encontrados):
                percentuais_encontrados.append({
                    'valor': valor,
                    'contexto': contexto_completo[:200],
                    'prioridade': 5
                })
    
    if percentuais_encontrados:
        # Ordenar por prioridade e limitar a 8 itens mais relevantes
        percentuais_encontrados = sorted(percentuais_encontrados, key=lambda x: x['prioridade'], reverse=True)[:8]
        
        valores = []
        for p in percentuais_encontrados:
            contexto_limpo = p['contexto'].replace('\n', ' ').strip()
            if contexto_limpo:
                valores.append(f"{p['valor']}% ‚Üí {contexto_limpo}")
        
        if valores:
            dados.append({
                'categoria': 'üìà Indicadores de Progresso',
                'descricao': 'Percentuais e m√©tricas identificados no documento:',
                'valores': valores
            })
    
    # Buscar informa√ß√µes de prazo e status (evitar duplicatas e dados gen√©ricos)
    status_info = {}
    padroes_status = [
        (r'status:?\s*([^\n.]{5,100})', 'Status'),
        (r'situa√ß√£o:?\s*([^\n.]{5,100})', 'Situa√ß√£o'),
        (r'respons√°vel:?\s*([^\n.]{3,80})', 'Respons√°vel'),
    ]
    
    for linha in linhas:
        # Ignorar linhas com palavras irrelevantes
        if any(palavra in linha.lower() for palavra in palavras_irrelevantes):
            continue
            
        for padrao, categoria in padroes_status:
            if categoria not in status_info:  # Evitar duplicatas de categoria
                matches = re.findall(padrao, linha, re.IGNORECASE)
                if matches:
                    info = matches[0] if isinstance(matches[0], str) else matches[0][0]
                    info_limpa = info.strip()[:150]
                    
                    # Validar que n√£o √© gen√©rico demais
                    if info_limpa and len(info_limpa) > 5:
                        # Deve conter letras reais
                        if re.search(r'[a-zA-Z√Ä-√ø]{3,}', info_limpa):
                            status_info[categoria] = info_limpa
    
    if status_info:
        valores_formatados = [f"{cat}: {val}" for cat, val in status_info.items()]
        dados.append({
            'categoria': '‚ÑπÔ∏è Informa√ß√µes do Projeto',
            'descricao': 'Detalhes identificados no documento:',
            'valores': valores_formatados
        })
    
    # Buscar datas espec√≠ficas (sem duplicatas)
    datas_encontradas = set()
    padroes_data = [
        r'\b(\d{1,2}/\d{1,2}/\d{4})\b',  # Datas dd/mm/yyyy
    ]
    
    for linha in linhas:
        # Ignorar linhas com palavras irrelevantes
        if any(palavra in linha.lower() for palavra in palavras_irrelevantes):
            continue
            
        for padrao in padroes_data:
            matches = re.findall(padrao, linha)
            for data in matches[:5]:
                datas_encontradas.add(data)
    
    if datas_encontradas and len(datas_encontradas) <= 10:  # Limitar para evitar lixo
        dados.append({
            'categoria': 'üìÖ Prazos e Datas',
            'descricao': 'Datas identificadas no documento:',
            'valores': sorted(list(datas_encontradas))[:5]
        })
    
    return dados if dados else None

def _extrair_palavras_chave(texto):
    """Extrai palavras-chave relevantes e espec√≠ficas do texto"""
    import re
    from collections import Counter
    
    # Lista expandida de stop words
    stop_words = {'de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'n√£o', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', '√†', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'j√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'voc√™', 'essa', 'num', 'nem', 'suas', 'meu', '√†s', 'minha', 'numa', 'pelos', 'elas', 'qual', 'n√≥s', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'sido', 'sendo', 'estar', 'sobre', 'pode', 'fazer', 'cada', 'outro', 'outra', 'outros', 'outras', 'bem', 'ainda', 'onde', 'enquanto', 'antes', 'ap√≥s', 'todas', 'todos', 'qualquer', 'algum', 'alguma', 'alguns', 'algumas', 'nenhum', 'nenhuma', 'mesmo', 'mesma', 'mesmos', 'mesmas'}
    
    # Termos gen√©ricos de documentos que devem ser filtrados
    termos_genericos = {'documento', 'relat√≥rio', 'an√°lise', 'arquivo', 'conte√∫do', 'informa√ß√£o', 'dados', 'sistema', 'projeto', 'seguinte', 'execu√ß√£o', 'exemplo', 'forma', 'parte', 'atrav√©s', 'devido', 'conforme', 'segundo', 'durante', 'desta', 'deste', 'dessa', 'desse'}
    
    # Extrair apenas substantivos e termos t√©cnicos (5+ caracteres)
    palavras = re.findall(r'\b[A-Z√Å√Ä√Ç√É√â√à√ä√ç√è√ì√î√ï√ñ√ö√á√ë][a-z√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±]{4,}\b', texto)
    
    # Filtrar stop words e termos gen√©ricos
    palavras_filtradas = [
        p.lower() for p in palavras 
        if p.lower() not in stop_words and p.lower() not in termos_genericos
    ]
    
    # Contar frequ√™ncia
    contador = Counter(palavras_filtradas)
    
    # Priorizar palavras que aparecem mais de uma vez
    palavras_relevantes = [
        palavra for palavra, freq in contador.most_common(20)
        if freq >= 2  # Aparecem pelo menos 2 vezes
    ]
    
    # Se n√£o houver palavras repetidas suficientes, pegar as mais comuns
    if len(palavras_relevantes) < 5:
        palavras_relevantes = [palavra for palavra, _ in contador.most_common(10)]
    
    # Capitalizar primeira letra
    return [palavra.capitalize() for palavra in palavras_relevantes[:10]]

def _gerar_relatorio_basico(conteudo, prompt_personalizado):
    """Gera um relat√≥rio b√°sico caso a IA falhe"""
    
    # Extrair primeiras frases do conte√∫do
    frases = conteudo.split('.')[:5]
    resumo_basico = '. '.join(frases) + '.'
    
    relatorio = f"""# üìä Relat√≥rio Executivo

## üéØ Resumo do Documento

{resumo_basico}

## üîç An√°lise

O documento apresenta informa√ß√µes relevantes que requerem an√°lise detalhada. 
Principais aspectos identificados:

- Conte√∫do estruturado com dados importantes
- Informa√ß√µes que necessitam de avalia√ß√£o estrat√©gica
- Pontos que podem impactar decis√µes futuras

"""
    
    if prompt_personalizado:
        relatorio += f"""## üìå Foco Solicitado

{prompt_personalizado}

"""
    
    relatorio += """---

*Nota: Este √© um relat√≥rio b√°sico gerado automaticamente. Para an√°lise mais profunda, 
recomenda-se revis√£o manual do documento.*
"""
    
    return relatorio


def extrair_conceitos_chave(texto, max_conceitos=3):
    """
    Extrai os conceitos-chave mais importantes de um texto.
    
    Args:
        texto: Texto para an√°lise
        max_conceitos: N√∫mero m√°ximo de conceitos a extrair
        
    Returns:
        list: Lista de conceitos-chave
    """
    # Palavras-chave t√©cnicas relevantes
    palavras_relevantes = [
        'dados', 'an√°lise', 'integra√ß√£o', 'riscos', 'gest√£o', 'monitoramento',
        'indicadores', 'desempenho', 'automa√ß√£o', 'ETL', 'API', 'dashboard',
        'relat√≥rios', 'm√©tricas', 'qualidade', 'consist√™ncia', 'alertas',
        'governan√ßa', 'compliance', 'estrat√©gia', 'otimiza√ß√£o', 'processos',
        'efici√™ncia', 'performance', 'confiabilidade', 'seguran√ßa'
    ]
    
    texto_lower = texto.lower()
    conceitos_encontrados = []
    
    for palavra in palavras_relevantes:
        if palavra in texto_lower and palavra not in conceitos_encontrados:
            conceitos_encontrados.append(palavra)
            if len(conceitos_encontrados) >= max_conceitos:
                break
    
    return conceitos_encontrados


def extrair_frase_principal(texto):
    """
    Extrai a primeira frase significativa do texto.
    
    Args:
        texto: Texto para an√°lise
        
    Returns:
        str: Primeira frase relevante
    """
    # Dividir em frases
    frases = re.split(r'[.!?]\s+', texto)
    
    # Retornar a primeira frase com mais de 20 caracteres
    for frase in frases:
        if len(frase.strip()) > 20:
            return frase.strip()
    
    return texto[:150].strip()


def gerar_insight_estruturado(texto_resumo, texto_desafios):
    """
    Gera um insight estruturado com gram√°tica perfeita usando templates e extra√ß√£o de conceitos.
    
    Args:
        texto_resumo: Texto do resumo executivo
        texto_desafios: Texto dos principais desafios
        
    Returns:
        str: Insight gerado com gram√°tica correta
    """
    try:
        # Extrair conceitos-chave do resumo
        conceitos_resumo = extrair_conceitos_chave(texto_resumo, max_conceitos=3)
        
        # Extrair conceitos-chave dos desafios
        conceitos_desafios = extrair_conceitos_chave(texto_desafios, max_conceitos=2)
        
        # Extrair frase principal do resumo
        frase_principal = extrair_frase_principal(texto_resumo)
        
        # Construir insight estruturado
        partes_insight = []
        
        # Parte 1: Foco principal
        if conceitos_resumo:
            if len(conceitos_resumo) == 1:
                conceitos_str = conceitos_resumo[0]
            elif len(conceitos_resumo) == 2:
                conceitos_str = f"{conceitos_resumo[0]} e {conceitos_resumo[1]}"
            else:
                conceitos_str = ", ".join(conceitos_resumo[:-1]) + f" e {conceitos_resumo[-1]}"
            
            partes_insight.append(f"Projeto focado em {conceitos_str}")
        else:
            # Usar frase principal como fallback
            partes_insight.append(frase_principal[:100])
        
        # Parte 2: Desafios principais
        if conceitos_desafios:
            if len(conceitos_desafios) == 1:
                desafios_str = conceitos_desafios[0]
            else:
                desafios_str = f"{conceitos_desafios[0]} e {conceitos_desafios[1]}"
            
            partes_insight.append(f"com desafios relacionados a {desafios_str}")
        
        # Parte 3: Objetivo estrat√©gico (baseado no contexto)
        if 'dados' in conceitos_resumo or 'an√°lise' in conceitos_resumo:
            partes_insight.append("visando suporte √† tomada de decis√£o estrat√©gica")
        elif 'riscos' in conceitos_resumo or 'gest√£o' in conceitos_resumo:
            partes_insight.append("para garantir opera√ß√µes seguras e eficientes")
        elif 'indicadores' in conceitos_resumo or 'monitoramento' in conceitos_resumo:
            partes_insight.append("permitindo acompanhamento cont√≠nuo de resultados e performance")
        elif 'automa√ß√£o' in conceitos_resumo or 'processos' in conceitos_resumo:
            partes_insight.append("otimizando processos e aumentando a efici√™ncia operacional")
        
        # Combinar todas as partes
        insight = ", ".join(partes_insight) + "."
        
        # Garantir primeira letra mai√∫scula
        insight = insight[0].upper() + insight[1:]
        
        return insight
        
    except Exception as e:
        logging.error(f"Erro ao gerar insight estruturado: {str(e)}")
        return "Insight n√£o dispon√≠vel no momento."

# --- Fun√ß√£o de Conex√£o (Helper) ---
def get_db_connection():
    try:
        conexao = sqlite3.connect(CAMINHO_BANCO)
        conexao.row_factory = sqlite3.Row # Para acessar por nome
        return conexao
    except Exception as e:
        print(f"Erro ao conectar ao banco: {e}")
        return None

# --- ETAPA 2: Processar os Dados ---
def gerar_insight_para_projeto(projeto_id=None, texto_resumo=None, texto_desafios=None):
    """
    Gera insight estruturado para um projeto espec√≠fico
    
    Args:
        projeto_id: ID do projeto (se fornecido, busca do banco)
        texto_resumo: Texto do resumo executivo (opcional)
        texto_desafios: Texto dos desafios (opcional)
    
    Returns:
        String com o insight gerado ou None se falhar
    """
    # Se projeto_id foi fornecido, buscar do banco
    if projeto_id:
        conexao = get_db_connection()
        if conexao is None:
            return None
        
        try:
            cursor = conexao.cursor()
            cursor.execute("""
                SELECT resumo_executivo, principais_desafios 
                FROM projetos WHERE id = ?
            """, (projeto_id,))
            
            projeto = cursor.fetchone()
            if projeto:
                texto_resumo = projeto['resumo_executivo']
                texto_desafios = projeto['principais_desafios']
        finally:
            conexao.close()
    
    # Verificar se temos texto para processar
    if not texto_resumo and not texto_desafios:
        logging.warning("Nenhum texto dispon√≠vel para gerar insight")
        return None
    
    # Usar valores padr√£o se algum estiver vazio
    if not texto_resumo:
        texto_resumo = "Projeto em desenvolvimento"
    if not texto_desafios:
        texto_desafios = "Sem desafios registrados"
    
    try:
        # Gerar insight estruturado
        insight_texto = gerar_insight_estruturado(texto_resumo, texto_desafios)
        logging.info(f"Insight gerado: {insight_texto}")
        
        # Se projeto_id foi fornecido, salvar no banco
        if projeto_id:
            conexao = get_db_connection()
            if conexao:
                try:
                    cursor = conexao.cursor()
                    cursor.execute(
                        "UPDATE projetos SET resumo_ia = ? WHERE id = ?",
                        (insight_texto, projeto_id)
                    )
                    conexao.commit()
                    logging.info(f"Insight salvo para projeto ID {projeto_id}")
                finally:
                    conexao.close()
        
        return insight_texto
        
    except Exception as e:
        logging.error(f"Erro ao gerar insight: {e}")
        return None

def gerar_insights():
    """Processa todos os projetos sem insights de IA"""
    conexao = get_db_connection()
    if conexao is None:
        return

    try:
        cursor = conexao.cursor()
        
        # Selecionamos projetos que t√™m um resumo, mas AINDA N√ÉO t√™m um insight de IA
        cursor.execute("""
            SELECT id, nome_projeto, resumo_executivo, principais_desafios 
            FROM projetos 
            WHERE resumo_ia IS NULL 
            AND (resumo_executivo IS NOT NULL OR principais_desafios IS NOT NULL)
        """)
        
        projetos_para_processar = cursor.fetchall()
        
        if not projetos_para_processar:
            print("Nenhum projeto novo para processar. O banco j√° est√° atualizado.")
            return

        print(f"Encontrados {len(projetos_para_processar)} projetos para gerar insights...")

        for projeto in projetos_para_processar:
            insight_texto = gerar_insight_para_projeto(
                projeto_id=projeto['id'],
                texto_resumo=projeto['resumo_executivo'],
                texto_desafios=projeto['principais_desafios']
            )
            
            if insight_texto:
                print(f"Insight gerado para '{projeto['nome_projeto']}': {insight_texto}")

        conexao.commit()
        print(f"Sucesso! {len(projetos_para_processar)} projetos atualizados com insights.")

    except Exception as e:
        print(f"ERRO durante o processamento dos insights: {e}")
        if conexao:
            conexao.rollback()
    finally:
        if conexao:
            conexao.close()
            print("Conex√£o com o banco fechada.")

# --- Executa a fun√ß√£o principal ---
if __name__ == "__main__":
    gerar_insights()